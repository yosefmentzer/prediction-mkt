{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1tKK6PAx-Uw"
   },
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_rC-XSgyBch"
   },
   "source": [
    "Objective: \n",
    "- get [Betfair historical data](https://historicdata.betfair.com/#/home) for the `match odds` (who will win) market.  \n",
    "\n",
    "Notes:  \n",
    "- get `metadata` on: available months/years, countries, number of files, sizes, etc.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dPkvsXd37Z1"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdIYlf0YeU3W"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-SX3dFfmeR3f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# requests\n",
    "import requests\n",
    "# credentials (for the API)\n",
    "import configparser\n",
    "# dates\n",
    "import calendar\n",
    "# asynchronous requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import aiofiles\n",
    "# files, system\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZSkeEcWXaRA"
   },
   "source": [
    "## Credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJtvtq7YuYv1"
   },
   "source": [
    " A valid [session token](https://developer.betfair.com/exchange-api/accounts-api-demo/) must be in `credentials.ini`, under `token`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PioyneeoVLb2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cred = configparser.ConfigParser()\n",
    "cred.read('credentials.ini')\n",
    "token = cred['DB']['token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDM7EW2N3y5i"
   },
   "source": [
    "# API endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnrpOp8YYJGU"
   },
   "source": [
    "reference: https://historicdata.betfair.com/#/apidocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSIutsgSa85F"
   },
   "source": [
    "Endpoints:  \n",
    "- `GetMyData` - Returns the packages you have purchased  \n",
    "- `GetCollectionOptions` - Returns the filter options for a given filter  \n",
    "- `GetAdvBasketDataSize` - Returns a file count and size based on a filter  \n",
    "- `DownloadListOfFiles` - Returns a list of files based on a filter  \n",
    "- `DownloadFile` - Downloads a specific file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we will:\n",
    "1. check data packages and dates available with `GetMyData`.  \n",
    "2. get countries available for each month with `GetCollectionOptions`.  \n",
    "3. get file counts and sizes per month of data with `GetAdvBasketDataSize`.  \n",
    "4. get list of data files with `DownloadListOfFiles`.  \n",
    "5. download data files with `DownloadFile`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBprxLoB4tth"
   },
   "source": [
    "# Check data packages and dates available with `GetMyData`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8afLQxu84KP"
   },
   "source": [
    "Make sure that:  \n",
    "- Packages from 04-2015 to 12-2022 are available.  \n",
    "- There are no missing months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# session object\n",
    "session = requests.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UYJGYSJrcamk",
    "outputId": "e7dbe455-6828-4d33-fd0e-fd4bf9c44bcd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "URL_GETMYDATA = \"https://historicdata.betfair.com/api/GetMyData\"\n",
    "\n",
    "headers = {\n",
    "    \"ssoid\": token,\n",
    "    'Accept': 'application/json'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resp = session.get(URL_GETMYDATA, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,\n",
       " '[{\"sport\":\"Horse Racing\",\"plan\":\"Basic Plan\",\"forDate\":\"2018-10-01T00:00:00\",\"purchaseItemId\":27728}')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check response code and first 100 characters\n",
    "resp.status_code, resp.text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T13:08:36.878004Z",
     "iopub.status.busy": "2023-01-30T13:08:36.877003Z",
     "iopub.status.idle": "2023-01-30T13:08:36.907003Z",
     "shell.execute_reply": "2023-01-30T13:08:36.904010Z",
     "shell.execute_reply.started": "2023-01-30T13:08:36.877003Z"
    }
   },
   "source": [
    "We seem to have received a legitimate response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "purchased_packages_dic = resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us export the data as a `JSON` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PURCHASED_PACKAGES_PATH = \"../data/raw/betfair/purchased_packages_dic.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(PURCHASED_PACKAGES_PATH, \"w\") as outfile:\n",
    "    json.dump(purchased_packages_dic, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `JSON` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(file=PURCHASED_PACKAGES_PATH, mode=\"r\") as f:\n",
    "    purchased_packages_dic = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check using `pandas` which months and years are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "0yWHEdOretlq",
    "outputId": "f441bccb-9603-4eb5-ad53-16828bd6c796",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sport</th>\n",
       "      <th>plan</th>\n",
       "      <th>forDate</th>\n",
       "      <th>purchaseItemId</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soccer</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>32270</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soccer</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>32270</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Soccer</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>32270</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Soccer</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>32269</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Soccer</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>29416</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Soccer</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>120990</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Soccer</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>120993</td>\n",
       "      <td>9</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Soccer</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>120996</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Soccer</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>120999</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Soccer</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>121002</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sport        plan    forDate  purchaseItemId  month  year\n",
       "2    Soccer  Basic Plan 2015-04-01           32270      4  2015\n",
       "3    Soccer  Basic Plan 2015-05-01           32270      5  2015\n",
       "4    Soccer  Basic Plan 2015-06-01           32270      6  2015\n",
       "5    Soccer  Basic Plan 2015-07-01           32269      7  2015\n",
       "6    Soccer  Basic Plan 2015-08-01           29416      8  2015\n",
       "..      ...         ...        ...             ...    ...   ...\n",
       "102  Soccer  Basic Plan 2023-08-01          120990      8  2023\n",
       "103  Soccer  Basic Plan 2023-09-01          120993      9  2023\n",
       "104  Soccer  Basic Plan 2023-10-01          120996     10  2023\n",
       "105  Soccer  Basic Plan 2023-11-01          120999     11  2023\n",
       "106  Soccer  Basic Plan 2023-12-01          121002     12  2023\n",
       "\n",
       "[105 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build pandas DataFrame\n",
    "purchased_packages = pd.DataFrame(purchased_packages_dic)\n",
    "purchased_packages_soccer = purchased_packages[purchased_packages['sport'] == 'Soccer'].copy()\n",
    "purchased_packages_soccer['forDate'] = pd.to_datetime(purchased_packages_soccer['forDate'])\n",
    "purchased_packages_soccer['month'] = purchased_packages_soccer['forDate'].dt.month\n",
    "purchased_packages_soccer['year'] = purchased_packages_soccer['forDate'].dt.year\n",
    "purchased_packages_soccer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2015             [4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
       "2016    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
       "2017    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
       "2018    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
       "2019    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
       "2020    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
       "2021    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
       "2022    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
       "2023    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
       "Name: month, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchased_packages_soccer.groupby(by=['year'])['month'].aggregate(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: Packages from 04-2015 to 12-2022 are available and there are no missing months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJUySxfb4wcj"
   },
   "source": [
    "# Get countries available for each month with `GetCollectionOptions`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "035w2Udg_i3z"
   },
   "source": [
    "For each month, get available countries and number of files.  \n",
    "Each file is one match or part of one match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peforming synchronous `requests` takes around 20min, so we work asynchronously with `aiohttp` and `asyncio`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "SPORT = 'Soccer'\n",
    "PLAN = 'Basic Plan'\n",
    "MARKET_TYPE = 'MATCH_ODDS'\n",
    "FILE_TYPE = 'M'\n",
    "LAST_DAY_INDEX = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# months and years\n",
    "months = purchased_packages_soccer['month']\n",
    "years = purchased_packages_soccer['year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make post requests per pair `month_year`, we need a list of `data` dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list of 'data' dictionaries for requests\n",
    "data_list = []\n",
    "\n",
    "for month, year in zip(months, years):\n",
    "    data = {\n",
    "        \"sport\": SPORT, \n",
    "        \"plan\": PLAN,\n",
    "        \"fromDay\": 1,\n",
    "        \"marketTypesCollection\": [MARKET_TYPE],\n",
    "        \"fileTypeCollection\" : [FILE_TYPE],\n",
    "        \"fromMonth\": month,\n",
    "        \"fromYear\": year,\n",
    "        \"toDay\": calendar.monthrange(year, month)[LAST_DAY_INDEX],\n",
    "        \"toMonth\": month,\n",
    "        \"toYear\": year\n",
    "        }\n",
    "\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "URL_COLLECTION_OPTIONS = \"https://historicdata.betfair.com/api/GetCollectionOptions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define 2 functions:  \n",
    "- one to asynchronously make a single POST request\n",
    "- one to wrap a list of requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def async_make_post_request(session, url, data, headers, timeout, retries):\n",
    "    \"\"\"\n",
    "    Make an asynchronous POST request with retries.\n",
    "    \n",
    "    Parameters:\n",
    "        - session (aiohttp.ClientSession): Asynchronous session object.\n",
    "        - url (str): URL for the request.\n",
    "        - data (dict): Data to be sent with the request.\n",
    "        - headers (dict): Headers for the request.\n",
    "        - timeout (int): Timeout for the request.\n",
    "        - retries (int): Number of retries if the request fails.\n",
    "    \n",
    "    Returns:\n",
    "        - response (dict): JSON response of the request if successful.\n",
    "        - None: If the request is unsuccessful.\n",
    "    \"\"\"\n",
    "    \n",
    "    retry_count = 0\n",
    "    while retry_count < retries:\n",
    "        try:\n",
    "            async with session.post(url, json=data, headers=headers, timeout=timeout) as response:\n",
    "                if response.status != 200:\n",
    "                    retry_count += 1\n",
    "                    continue\n",
    "                return await response.json()\n",
    "        except (aiohttp.ClientError, asyncio.TimeoutError, json.JSONDecodeError):\n",
    "            retry_count += 1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def async_make_multiple_post_requests(url, data_list, headers, timeout=5, retries=20):\n",
    "    \"\"\"\n",
    "    Make multiple asynchronous POST requests with retries.\n",
    "    \n",
    "    Parameters:\n",
    "        - url (str): URL for the requests.\n",
    "        - data_list (list): list of data dictionaries to be sent with each request.\n",
    "        - headers (dict): Headers for the requests.\n",
    "        - timeout (int): Timeout for the requests.\n",
    "        - retries (int): Number of retries if the requests fail.\n",
    "    \n",
    "    Returns:\n",
    "        - results (list): list of JSON responses of the requests if successful.\n",
    "    \"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [async_make_post_request(session, url, data, headers, timeout, retries)\n",
    "                 for data in data_list]\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=False)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = await async_make_multiple_post_requests(URL_COLLECTION_OPTIONS, data_list, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all requests were successful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None in results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case not all requests were successful, we write a function to perform retry cycles on failed requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:00:22.606894Z",
     "iopub.status.busy": "2023-02-02T18:00:22.605892Z",
     "iopub.status.idle": "2023-02-02T18:00:22.623894Z",
     "shell.execute_reply": "2023-02-02T18:00:22.621893Z",
     "shell.execute_reply.started": "2023-02-02T18:00:22.606894Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_none_idx(results):\n",
    "    \"\"\"\n",
    "    Get indices of failed requests in a given `results` list.\n",
    "    \"\"\"\n",
    "    none_idx = []\n",
    "    for i, r in enumerate(results):\n",
    "        if r is None:\n",
    "            none_idx.append(i)\n",
    "    return none_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:00:26.583114Z",
     "iopub.status.busy": "2023-02-02T18:00:26.582116Z",
     "iopub.status.idle": "2023-02-02T18:00:26.613115Z",
     "shell.execute_reply": "2023-02-02T18:00:26.611118Z",
     "shell.execute_reply.started": "2023-02-02T18:00:26.583114Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def retry_failed_requests(url, data_list, headers, results, timeout=5, retries=20, max_retry_cycles=10):\n",
    "    \"\"\"\n",
    "    Perform retry cycles on the failed requests.\n",
    "    \n",
    "    Parameters:\n",
    "    - url (str): URL for the requests.\n",
    "    - data_list (list): list of data dictionaries to be sent with each request.\n",
    "    - results (list): list of previous JSON responses of the requests if successful.\n",
    "    - max_retry_cycles (int): maximum number of cycles if there still are failed requests.\n",
    "    \n",
    "    Returns:\n",
    "        - results (list): updated list of JSON responses of the requests if successful.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    while ((None in results) and (count < max_retry_cycles)):\n",
    "        none_idx = get_none_idx(results)\n",
    "        results_retry = await async_make_multiple_post_requests(url,\n",
    "                                                                [data_list[i] for i in none_idx],\n",
    "                                                                headers,\n",
    "                                                                timeout,\n",
    "                                                                retries)\n",
    "        for i, j in enumerate(none_idx):\n",
    "            results[j] = results_retry[i]\n",
    "        count +=1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:00:33.421782Z",
     "iopub.status.busy": "2023-02-02T18:00:33.421782Z",
     "iopub.status.idle": "2023-02-02T18:04:53.054890Z",
     "shell.execute_reply": "2023-02-02T18:04:53.053967Z",
     "shell.execute_reply.started": "2023-02-02T18:00:33.421782Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = await retry_failed_requests(URL_COLLECTION_OPTIONS, data_list, headers, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:10:37.637672Z",
     "iopub.status.busy": "2023-02-02T18:10:37.636675Z",
     "iopub.status.idle": "2023-02-02T18:10:37.657671Z",
     "shell.execute_reply": "2023-02-02T18:10:37.655669Z",
     "shell.execute_reply.started": "2023-02-02T18:10:37.637672Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None in results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All requests were successful. We needed a high value for RETRIES (20) due to timeout errors.  \n",
    "Now let us store the results in a dictionary with `month_year` pairs as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:10:46.326527Z",
     "iopub.status.busy": "2023-02-02T18:10:46.324524Z",
     "iopub.status.idle": "2023-02-02T18:10:46.349526Z",
     "shell.execute_reply": "2023-02-02T18:10:46.347531Z",
     "shell.execute_reply.started": "2023-02-02T18:10:46.326527Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys = ['_'.join([str(m), str(y)]) for m, y in zip(months, years)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:11:17.951275Z",
     "iopub.status.busy": "2023-02-02T18:11:17.950275Z",
     "iopub.status.idle": "2023-02-02T18:11:17.974282Z",
     "shell.execute_reply": "2023-02-02T18:11:17.972296Z",
     "shell.execute_reply.started": "2023-02-02T18:11:17.951275Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection_options = {k: r for k, r in zip(keys, results)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us export the data as a `JSON` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:11:26.533496Z",
     "iopub.status.busy": "2023-02-02T18:11:26.532493Z",
     "iopub.status.idle": "2023-02-02T18:11:26.555494Z",
     "shell.execute_reply": "2023-02-02T18:11:26.553498Z",
     "shell.execute_reply.started": "2023-02-02T18:11:26.532493Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "COLLECTION_OPTIONS_PATH = \"../data/raw/betfair/collection_options.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:11:26.562496Z",
     "iopub.status.busy": "2023-02-02T18:11:26.561493Z",
     "iopub.status.idle": "2023-02-02T18:11:26.954497Z",
     "shell.execute_reply": "2023-02-02T18:11:26.951495Z",
     "shell.execute_reply.started": "2023-02-02T18:11:26.562496Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(COLLECTION_OPTIONS_PATH, \"w\") as outfile:\n",
    "    json.dump(collection_options, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the `JSON` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:11:31.390311Z",
     "iopub.status.busy": "2023-02-02T18:11:31.389312Z",
     "iopub.status.idle": "2023-02-02T18:11:31.437305Z",
     "shell.execute_reply": "2023-02-02T18:11:31.435306Z",
     "shell.execute_reply.started": "2023-02-02T18:11:31.390311Z"
    },
    "id": "viUeS5HBGkMe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(file=COLLECTION_OPTIONS_PATH, mode=\"r\") as f:\n",
    "    collection_options = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how a record looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:11:33.142794Z",
     "iopub.status.busy": "2023-02-02T18:11:33.142794Z",
     "iopub.status.idle": "2023-02-02T18:11:33.201801Z",
     "shell.execute_reply": "2023-02-02T18:11:33.199794Z",
     "shell.execute_reply.started": "2023-02-02T18:11:33.142794Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'marketTypesCollection': [{'name': 'MATCH_ODDS', 'count': 11133}],\n",
       " 'countriesCollection': [{'name': 'PY', 'count': 67},\n",
       "  {'name': 'BR', 'count': 467},\n",
       "  {'name': 'SV', 'count': 79},\n",
       "  {'name': 'CO', 'count': 110},\n",
       "  {'name': 'FR', 'count': 266},\n",
       "  {'name': 'IL', 'count': 200},\n",
       "  {'name': 'CZ', 'count': 232},\n",
       "  {'name': 'UA', 'count': 155},\n",
       "  {'name': 'RU', 'count': 264},\n",
       "  {'name': 'AZ', 'count': 25},\n",
       "  {'name': 'IQ', 'count': 3},\n",
       "  {'name': 'UZ', 'count': 49},\n",
       "  {'name': 'JP', 'count': 225},\n",
       "  {'name': 'IE', 'count': 80},\n",
       "  {'name': 'IN', 'count': 44},\n",
       "  {'name': 'CN', 'count': 59},\n",
       "  {'name': 'SG', 'count': 51},\n",
       "  {'name': 'GB', 'count': 1479},\n",
       "  {'name': 'IT', 'count': 435},\n",
       "  {'name': 'JO', 'count': 40},\n",
       "  {'name': 'MY', 'count': 53},\n",
       "  {'name': 'VE', 'count': 109},\n",
       "  {'name': 'RO', 'count': 178},\n",
       "  {'name': 'CS', 'count': 67},\n",
       "  {'name': 'SK', 'count': 90},\n",
       "  {'name': '', 'count': 76},\n",
       "  {'name': 'KW', 'count': 37},\n",
       "  {'name': 'QA', 'count': 39},\n",
       "  {'name': 'FI', 'count': 77},\n",
       "  {'name': 'AE', 'count': 56},\n",
       "  {'name': 'BY', 'count': 67},\n",
       "  {'name': 'PL', 'count': 197},\n",
       "  {'name': 'EE', 'count': 70},\n",
       "  {'name': 'HR', 'count': 72},\n",
       "  {'name': 'DK', 'count': 189},\n",
       "  {'name': 'MA', 'count': 40},\n",
       "  {'name': 'LT', 'count': 34},\n",
       "  {'name': 'SA', 'count': 38},\n",
       "  {'name': 'IS', 'count': 57},\n",
       "  {'name': 'AT', 'count': 105},\n",
       "  {'name': 'DE', 'count': 557},\n",
       "  {'name': 'NO', 'count': 329},\n",
       "  {'name': 'BG', 'count': 48},\n",
       "  {'name': 'MT', 'count': 28},\n",
       "  {'name': 'BE', 'count': 162},\n",
       "  {'name': 'NL', 'count': 204},\n",
       "  {'name': 'PT', 'count': 246},\n",
       "  {'name': 'AR', 'count': 329},\n",
       "  {'name': 'GI', 'count': 24},\n",
       "  {'name': 'ES', 'count': 1201},\n",
       "  {'name': 'PE', 'count': 48},\n",
       "  {'name': 'MX', 'count': 135},\n",
       "  {'name': 'US', 'count': 122},\n",
       "  {'name': 'BO', 'count': 26},\n",
       "  {'name': 'EC', 'count': 52},\n",
       "  {'name': 'PA', 'count': 10},\n",
       "  {'name': 'KR', 'count': 28},\n",
       "  {'name': 'HK', 'count': 46},\n",
       "  {'name': 'PH', 'count': 35},\n",
       "  {'name': 'HU', 'count': 92},\n",
       "  {'name': 'GR', 'count': 167},\n",
       "  {'name': 'VN', 'count': 59},\n",
       "  {'name': 'TH', 'count': 32},\n",
       "  {'name': 'AM', 'count': 36},\n",
       "  {'name': 'SE', 'count': 274},\n",
       "  {'name': 'TR', 'count': 152},\n",
       "  {'name': 'LV', 'count': 28},\n",
       "  {'name': 'KE', 'count': 16},\n",
       "  {'name': 'GE', 'count': 75},\n",
       "  {'name': 'SI', 'count': 42},\n",
       "  {'name': 'TN', 'count': 10},\n",
       "  {'name': 'EG', 'count': 48},\n",
       "  {'name': 'DZ', 'count': 10},\n",
       "  {'name': 'CL', 'count': 97},\n",
       "  {'name': 'CH', 'count': 66},\n",
       "  {'name': 'UY', 'count': 57},\n",
       "  {'name': 'GT', 'count': 22},\n",
       "  {'name': 'CR', 'count': 33},\n",
       "  {'name': 'HN', 'count': 11},\n",
       "  {'name': 'CA', 'count': 15},\n",
       "  {'name': 'FJ', 'count': 8},\n",
       "  {'name': 'BN', 'count': 2},\n",
       "  {'name': 'KZ', 'count': 21},\n",
       "  {'name': 'CM', 'count': 31},\n",
       "  {'name': 'PS', 'count': 8},\n",
       "  {'name': 'LU', 'count': 6},\n",
       "  {'name': 'MK', 'count': 3},\n",
       "  {'name': 'JM', 'count': 13},\n",
       "  {'name': 'BH', 'count': 20},\n",
       "  {'name': 'IR', 'count': 5},\n",
       "  {'name': 'LI', 'count': 2},\n",
       "  {'name': 'NI', 'count': 9},\n",
       "  {'name': 'MO', 'count': 10},\n",
       "  {'name': 'BA', 'count': 9},\n",
       "  {'name': 'MV', 'count': 3},\n",
       "  {'name': 'LB', 'count': 6},\n",
       "  {'name': 'TM', 'count': 1},\n",
       "  {'name': 'TJ', 'count': 2},\n",
       "  {'name': 'MM', 'count': 4},\n",
       "  {'name': 'LA', 'count': 2},\n",
       "  {'name': 'OM', 'count': 2},\n",
       "  {'name': 'SY', 'count': 3},\n",
       "  {'name': 'TW', 'count': 4},\n",
       "  {'name': 'KG', 'count': 3},\n",
       "  {'name': 'GH', 'count': 1},\n",
       "  {'name': 'BD', 'count': 2}],\n",
       " 'fileTypeCollection': [{'name': 'M', 'count': 11133}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_options['4_2016']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not perform an analysis per country at this moment, but the data is stored in case we need to analyze it ahead in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEo7f_zAyGQy"
   },
   "source": [
    "# Get file counts and sizes per month of data with `GetAdvBasketDataSize`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLzh1F4RB08J"
   },
   "source": [
    "For each month, get total size and number of files (before filtering).  \n",
    "We want to get the order of magnitude of the total size of Betfair data files and the number of files, for the set of relevant countries.  \n",
    "We use the list of relevant countries defined in the first round of the research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:11:39.623535Z",
     "iopub.status.busy": "2023-02-02T18:11:39.622533Z",
     "iopub.status.idle": "2023-02-02T18:11:39.638534Z",
     "shell.execute_reply": "2023-02-02T18:11:39.636535Z",
     "shell.execute_reply.started": "2023-02-02T18:11:39.623535Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "COUNTRY_CODES_PATH = 'configuration/countryCodes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:11:42.808011Z",
     "iopub.status.busy": "2023-02-02T18:11:42.806984Z",
     "iopub.status.idle": "2023-02-02T18:11:42.848991Z",
     "shell.execute_reply": "2023-02-02T18:11:42.845988Z",
     "shell.execute_reply.started": "2023-02-02T18:11:42.808011Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AR',\n",
       " 'AU',\n",
       " 'BR',\n",
       " 'CA',\n",
       " 'CN',\n",
       " 'DE',\n",
       " 'ES',\n",
       " 'FR',\n",
       " 'GB',\n",
       " 'IL',\n",
       " 'IT',\n",
       " 'JP',\n",
       " 'NL',\n",
       " 'PT',\n",
       " 'RU',\n",
       " 'TR',\n",
       " 'US']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_codes = list(pd.read_csv(COUNTRY_CODES_PATH)['marketDefinition.countryCode'].values)\n",
    "country_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the previous endpoint, we need a list of data dictionaries for the POST requests.  \n",
    "For `GetAdvBasketDataSize`, we restrict the requests to the list of relevant countries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:11:47.970483Z",
     "iopub.status.busy": "2023-02-02T18:11:47.969486Z",
     "iopub.status.idle": "2023-02-02T18:11:47.989483Z",
     "shell.execute_reply": "2023-02-02T18:11:47.987485Z",
     "shell.execute_reply.started": "2023-02-02T18:11:47.970483Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_list_countries = []\n",
    "\n",
    "for data in data_list:\n",
    "    data_countries = data.copy()\n",
    "    data_countries['countriesCollection'] = country_codes\n",
    "    data_list_countries.append(data_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:11:52.896190Z",
     "iopub.status.busy": "2023-02-02T18:11:52.895192Z",
     "iopub.status.idle": "2023-02-02T18:11:52.908188Z",
     "shell.execute_reply": "2023-02-02T18:11:52.906188Z",
     "shell.execute_reply.started": "2023-02-02T18:11:52.896190Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "URL_DATA_SIZE = \"https://historicdata.betfair.com/api/GetAdvBasketDataSize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:11:54.487306Z",
     "iopub.status.busy": "2023-02-02T18:11:54.487306Z",
     "iopub.status.idle": "2023-02-02T18:13:33.857319Z",
     "shell.execute_reply": "2023-02-02T18:13:33.854318Z",
     "shell.execute_reply.started": "2023-02-02T18:11:54.487306Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_data_size = await async_make_multiple_post_requests(URL_DATA_SIZE, data_list_countries, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T18:21:34.714016Z",
     "iopub.status.busy": "2023-02-02T18:21:34.713019Z",
     "iopub.status.idle": "2023-02-02T18:21:34.737017Z",
     "shell.execute_reply": "2023-02-02T18:21:34.735018Z",
     "shell.execute_reply.started": "2023-02-02T18:21:34.714016Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None in results_data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T22:55:53.551904Z",
     "iopub.status.busy": "2023-02-01T22:55:53.550904Z",
     "iopub.status.idle": "2023-02-01T22:55:53.580911Z",
     "shell.execute_reply": "2023-02-01T22:55:53.574903Z",
     "shell.execute_reply.started": "2023-02-01T22:55:53.551904Z"
    }
   },
   "source": [
    "Not all requests were successful, so we run a function to perform retry cycles on the failed requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T19:16:23.165910Z",
     "iopub.status.busy": "2023-02-02T19:16:23.164912Z",
     "iopub.status.idle": "2023-02-02T19:16:23.180907Z",
     "shell.execute_reply": "2023-02-02T19:16:23.178913Z",
     "shell.execute_reply.started": "2023-02-02T19:16:23.165910Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_data_size = await retry_failed_requests(URL_DATA_SIZE, data_list_countries, headers, results_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T19:16:31.979747Z",
     "iopub.status.busy": "2023-02-02T19:16:31.978752Z",
     "iopub.status.idle": "2023-02-02T19:16:31.999749Z",
     "shell.execute_reply": "2023-02-02T19:16:31.997750Z",
     "shell.execute_reply.started": "2023-02-02T19:16:31.979747Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None in results_data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T19:16:41.440565Z",
     "iopub.status.busy": "2023-02-02T19:16:41.439566Z",
     "iopub.status.idle": "2023-02-02T19:16:41.460564Z",
     "shell.execute_reply": "2023-02-02T19:16:41.457566Z",
     "shell.execute_reply.started": "2023-02-02T19:16:41.440565Z"
    }
   },
   "source": [
    "All requests were successful.  \n",
    "Let us see what the results look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T19:16:47.697216Z",
     "iopub.status.busy": "2023-02-02T19:16:47.696213Z",
     "iopub.status.idle": "2023-02-02T19:16:47.751215Z",
     "shell.execute_reply": "2023-02-02T19:16:47.749214Z",
     "shell.execute_reply.started": "2023-02-02T19:16:47.697216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'totalSizeMB': 0, 'fileCount': 17},\n",
       " {'totalSizeMB': 7, 'fileCount': 3028},\n",
       " {'totalSizeMB': 3, 'fileCount': 1028},\n",
       " {'totalSizeMB': 4, 'fileCount': 1702},\n",
       " {'totalSizeMB': 8, 'fileCount': 3905},\n",
       " {'totalSizeMB': 11, 'fileCount': 6242},\n",
       " {'totalSizeMB': 10, 'fileCount': 5236},\n",
       " {'totalSizeMB': 9, 'fileCount': 4706},\n",
       " {'totalSizeMB': 9, 'fileCount': 4303},\n",
       " {'totalSizeMB': 10, 'fileCount': 5255},\n",
       " {'totalSizeMB': 7, 'fileCount': 3500},\n",
       " {'totalSizeMB': 7, 'fileCount': 3700},\n",
       " {'totalSizeMB': 11, 'fileCount': 6221},\n",
       " {'totalSizeMB': 8, 'fileCount': 4235},\n",
       " {'totalSizeMB': 4, 'fileCount': 1539},\n",
       " {'totalSizeMB': 4, 'fileCount': 2012},\n",
       " {'totalSizeMB': 9, 'fileCount': 4404},\n",
       " {'totalSizeMB': 11, 'fileCount': 5521},\n",
       " {'totalSizeMB': 11, 'fileCount': 5614},\n",
       " {'totalSizeMB': 9, 'fileCount': 4609},\n",
       " {'totalSizeMB': 9, 'fileCount': 3949},\n",
       " {'totalSizeMB': 8, 'fileCount': 3927},\n",
       " {'totalSizeMB': 9, 'fileCount': 4301},\n",
       " {'totalSizeMB': 10, 'fileCount': 5043},\n",
       " {'totalSizeMB': 11, 'fileCount': 5832},\n",
       " {'totalSizeMB': 8, 'fileCount': 3827},\n",
       " {'totalSizeMB': 4, 'fileCount': 1803},\n",
       " {'totalSizeMB': 5, 'fileCount': 2188},\n",
       " {'totalSizeMB': 9, 'fileCount': 4295},\n",
       " {'totalSizeMB': 9, 'fileCount': 4528},\n",
       " {'totalSizeMB': 10, 'fileCount': 4900},\n",
       " {'totalSizeMB': 8, 'fileCount': 3943},\n",
       " {'totalSizeMB': 6, 'fileCount': 2914},\n",
       " {'totalSizeMB': 9, 'fileCount': 3607},\n",
       " {'totalSizeMB': 8, 'fileCount': 3522},\n",
       " {'totalSizeMB': 9, 'fileCount': 3698},\n",
       " {'totalSizeMB': 7, 'fileCount': 2849},\n",
       " {'totalSizeMB': 6, 'fileCount': 2309},\n",
       " {'totalSizeMB': 2, 'fileCount': 966},\n",
       " {'totalSizeMB': 3, 'fileCount': 1085},\n",
       " {'totalSizeMB': 8, 'fileCount': 3135},\n",
       " {'totalSizeMB': 8, 'fileCount': 3703},\n",
       " {'totalSizeMB': 9, 'fileCount': 3660},\n",
       " {'totalSizeMB': 8, 'fileCount': 3420},\n",
       " {'totalSizeMB': 8, 'fileCount': 2999},\n",
       " {'totalSizeMB': 8, 'fileCount': 3064},\n",
       " {'totalSizeMB': 8, 'fileCount': 3426},\n",
       " {'totalSizeMB': 9, 'fileCount': 4078},\n",
       " {'totalSizeMB': 9, 'fileCount': 3750},\n",
       " {'totalSizeMB': 6, 'fileCount': 2404},\n",
       " {'totalSizeMB': 2, 'fileCount': 910},\n",
       " {'totalSizeMB': 3, 'fileCount': 993},\n",
       " {'totalSizeMB': 8, 'fileCount': 3236},\n",
       " {'totalSizeMB': 9, 'fileCount': 3725},\n",
       " {'totalSizeMB': 8, 'fileCount': 3387},\n",
       " {'totalSizeMB': 8, 'fileCount': 3401},\n",
       " {'totalSizeMB': 8, 'fileCount': 2787},\n",
       " {'totalSizeMB': 8, 'fileCount': 3110},\n",
       " {'totalSizeMB': 10, 'fileCount': 3846},\n",
       " {'totalSizeMB': 5, 'fileCount': 2215},\n",
       " {'totalSizeMB': 0, 'fileCount': 15},\n",
       " {'totalSizeMB': 1, 'fileCount': 88},\n",
       " {'totalSizeMB': 3, 'fileCount': 672},\n",
       " {'totalSizeMB': 5, 'fileCount': 1163},\n",
       " {'totalSizeMB': 4, 'fileCount': 1214},\n",
       " {'totalSizeMB': 7, 'fileCount': 2326},\n",
       " {'totalSizeMB': 9, 'fileCount': 3451},\n",
       " {'totalSizeMB': 9, 'fileCount': 3679},\n",
       " {'totalSizeMB': 10, 'fileCount': 3582},\n",
       " {'totalSizeMB': 10, 'fileCount': 3211},\n",
       " {'totalSizeMB': 9, 'fileCount': 3014},\n",
       " {'totalSizeMB': 10, 'fileCount': 3501},\n",
       " {'totalSizeMB': 11, 'fileCount': 4100},\n",
       " {'totalSizeMB': 9, 'fileCount': 3604},\n",
       " {'totalSizeMB': 4, 'fileCount': 1726},\n",
       " {'totalSizeMB': 5, 'fileCount': 1826},\n",
       " {'totalSizeMB': 9, 'fileCount': 3352},\n",
       " {'totalSizeMB': 10, 'fileCount': 3970},\n",
       " {'totalSizeMB': 12, 'fileCount': 4806},\n",
       " {'totalSizeMB': 10, 'fileCount': 3964},\n",
       " {'totalSizeMB': 9, 'fileCount': 3478},\n",
       " {'totalSizeMB': 9, 'fileCount': 3515},\n",
       " {'totalSizeMB': 11, 'fileCount': 4003},\n",
       " {'totalSizeMB': 10, 'fileCount': 4146},\n",
       " {'totalSizeMB': 11, 'fileCount': 4221},\n",
       " {'totalSizeMB': 8, 'fileCount': 3180},\n",
       " {'totalSizeMB': 4, 'fileCount': 1485},\n",
       " {'totalSizeMB': 5, 'fileCount': 1671},\n",
       " {'totalSizeMB': 9, 'fileCount': 3113},\n",
       " {'totalSizeMB': 10, 'fileCount': 3979},\n",
       " {'totalSizeMB': 12, 'fileCount': 4504},\n",
       " {'totalSizeMB': 8, 'fileCount': 3059},\n",
       " {'totalSizeMB': 7, 'fileCount': 2764}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T19:16:56.610015Z",
     "iopub.status.busy": "2023-02-02T19:16:56.609018Z",
     "iopub.status.idle": "2023-02-02T19:16:56.635016Z",
     "shell.execute_reply": "2023-02-02T19:16:56.630020Z",
     "shell.execute_reply.started": "2023-02-02T19:16:56.610015Z"
    }
   },
   "source": [
    "Now let us store the results in a dictionary with `month_year` pairs as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T19:17:05.149224Z",
     "iopub.status.busy": "2023-02-02T19:17:05.148218Z",
     "iopub.status.idle": "2023-02-02T19:17:05.163219Z",
     "shell.execute_reply": "2023-02-02T19:17:05.161220Z",
     "shell.execute_reply.started": "2023-02-02T19:17:05.149224Z"
    }
   },
   "outputs": [],
   "source": [
    "sizes_counts = {k: r for k, r in zip(keys, results_data_size)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us export the data as a `JSON` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T19:17:10.253796Z",
     "iopub.status.busy": "2023-02-02T19:17:10.253796Z",
     "iopub.status.idle": "2023-02-02T19:17:10.267801Z",
     "shell.execute_reply": "2023-02-02T19:17:10.265799Z",
     "shell.execute_reply.started": "2023-02-02T19:17:10.253796Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SIZES_COUNTS_PATH = \"../data/raw/betfair/sizes_counts.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T19:17:11.837988Z",
     "iopub.status.busy": "2023-02-02T19:17:11.835982Z",
     "iopub.status.idle": "2023-02-02T19:17:11.862982Z",
     "shell.execute_reply": "2023-02-02T19:17:11.861002Z",
     "shell.execute_reply.started": "2023-02-02T19:17:11.837988Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(SIZES_COUNTS_PATH, \"w\") as outfile:\n",
    "    json.dump(sizes_counts, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us calculate totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T19:17:18.718263Z",
     "iopub.status.busy": "2023-02-02T19:17:18.717261Z",
     "iopub.status.idle": "2023-02-02T19:17:18.752260Z",
     "shell.execute_reply": "2023-02-02T19:17:18.750264Z",
     "shell.execute_reply.started": "2023-02-02T19:17:18.718263Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 712 MB.\n",
      "Total files: 303894.\n"
     ]
    }
   ],
   "source": [
    "total_size = 0\n",
    "total_files = 0\n",
    "\n",
    "for k, v in sizes_counts.items():\n",
    "    total_size += v['totalSizeMB']\n",
    "    total_files += v['fileCount']\n",
    "print(f'Total size: {total_size} MB.')\n",
    "print(f'Total files: {total_files}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load from `JSON` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T19:17:25.679788Z",
     "iopub.status.busy": "2023-02-02T19:17:25.678784Z",
     "iopub.status.idle": "2023-02-02T19:17:25.697785Z",
     "shell.execute_reply": "2023-02-02T19:17:25.694784Z",
     "shell.execute_reply.started": "2023-02-02T19:17:25.679788Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(file=SIZES_COUNTS_PATH, mode=\"r\") as f:\n",
    "    sizes_counts = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know the order of magnitude of the total size of Betfair data files and the number of files, for the set of relevant countries.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-BjYftazSi1"
   },
   "source": [
    "# Get list of data files with `DownloadListOfFiles`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXSUCdJmCP1K"
   },
   "source": [
    "For each month, get list of files for download, for the relevant set of countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T19:20:23.998576Z",
     "iopub.status.busy": "2023-02-02T19:20:23.997577Z",
     "iopub.status.idle": "2023-02-02T19:20:24.018577Z",
     "shell.execute_reply": "2023-02-02T19:20:24.016579Z",
     "shell.execute_reply.started": "2023-02-02T19:20:23.998576Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "URL_LIST_OF_FILES = \"https://historicdata.betfair.com/api/DownloadListOfFiles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T19:20:25.739923Z",
     "iopub.status.busy": "2023-02-02T19:20:25.738927Z",
     "iopub.status.idle": "2023-02-02T19:23:45.962336Z",
     "shell.execute_reply": "2023-02-02T19:23:45.961318Z",
     "shell.execute_reply.started": "2023-02-02T19:20:25.739923Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_list_of_files = await async_make_multiple_post_requests(URL_LIST_OF_FILES, data_list_countries, headers, timeout=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T19:24:18.996619Z",
     "iopub.status.busy": "2023-02-02T19:24:18.995616Z",
     "iopub.status.idle": "2023-02-02T19:24:19.017616Z",
     "shell.execute_reply": "2023-02-02T19:24:19.015617Z",
     "shell.execute_reply.started": "2023-02-02T19:24:18.996619Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None in results_list_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:01:50.080206Z",
     "iopub.status.busy": "2023-02-03T06:01:50.079205Z",
     "iopub.status.idle": "2023-02-03T06:20:27.964414Z",
     "shell.execute_reply": "2023-02-03T06:20:27.962437Z",
     "shell.execute_reply.started": "2023-02-03T06:01:50.080206Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_list_of_files = await retry_failed_requests(URL_LIST_OF_FILES, data_list_countries, headers, results_list_of_files, timeout=5, max_retry_cycles=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:26:12.821808Z",
     "iopub.status.busy": "2023-02-03T06:26:12.820813Z",
     "iopub.status.idle": "2023-02-03T06:26:12.847812Z",
     "shell.execute_reply": "2023-02-03T06:26:12.845807Z",
     "shell.execute_reply.started": "2023-02-03T06:26:12.821808Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None in results_list_of_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All requests were successful.\n",
    "Now let us store the results in a dictionary with `month_year` pairs as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:26:55.917948Z",
     "iopub.status.busy": "2023-02-03T06:26:55.915950Z",
     "iopub.status.idle": "2023-02-03T06:26:55.965948Z",
     "shell.execute_reply": "2023-02-03T06:26:55.961952Z",
     "shell.execute_reply.started": "2023-02-03T06:26:55.917948Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lists_of_files = {k: r for k, r in zip(keys, results_list_of_files)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us export the data as a `JSON` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:26:57.561224Z",
     "iopub.status.busy": "2023-02-03T06:26:57.560234Z",
     "iopub.status.idle": "2023-02-03T06:26:57.571228Z",
     "shell.execute_reply": "2023-02-03T06:26:57.569230Z",
     "shell.execute_reply.started": "2023-02-03T06:26:57.561224Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LISTS_OF_FILES_PATH = \"../data/raw/betfair/lists_of_files.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:26:59.426003Z",
     "iopub.status.busy": "2023-02-03T06:26:59.426003Z",
     "iopub.status.idle": "2023-02-03T06:27:01.384533Z",
     "shell.execute_reply": "2023-02-03T06:27:01.380529Z",
     "shell.execute_reply.started": "2023-02-03T06:26:59.426003Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(LISTS_OF_FILES_PATH, \"w\") as outfile:\n",
    "    json.dump(lists_of_files, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the `JSON` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:27:01.389532Z",
     "iopub.status.busy": "2023-02-03T06:27:01.388529Z",
     "iopub.status.idle": "2023-02-03T06:27:02.016530Z",
     "shell.execute_reply": "2023-02-03T06:27:02.013535Z",
     "shell.execute_reply.started": "2023-02-03T06:27:01.389532Z"
    },
    "id": "viUeS5HBGkMe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(file=LISTS_OF_FILES_PATH, mode=\"r\") as f:\n",
    "    lists_of_files = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T19:02:05.400440Z",
     "iopub.status.busy": "2023-01-30T19:02:05.399444Z",
     "iopub.status.idle": "2023-01-30T19:02:05.424437Z",
     "shell.execute_reply": "2023-01-30T19:02:05.419436Z",
     "shell.execute_reply.started": "2023-01-30T19:02:05.400440Z"
    }
   },
   "source": [
    "Let us see how a record looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:27:05.409231Z",
     "iopub.status.busy": "2023-02-03T06:27:05.408232Z",
     "iopub.status.idle": "2023-02-03T06:27:05.437232Z",
     "shell.execute_reply": "2023-02-03T06:27:05.435232Z",
     "shell.execute_reply.started": "2023-02-03T06:27:05.409231Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/xds_nfs/edp_processed/BASIC/2022/Oct/1/31772344/1.203873421.bz2',\n",
       " '/xds_nfs/edp_processed/BASIC/2022/Oct/1/31772343/1.203873511.bz2',\n",
       " '/xds_nfs/edp_processed/BASIC/2022/Oct/1/31761863/1.203677367.bz2',\n",
       " '/xds_nfs/edp_processed/BASIC/2022/Oct/1/31781522/1.204081256.bz2',\n",
       " '/xds_nfs/edp_processed/BASIC/2022/Oct/1/31772345/1.203873601.bz2',\n",
       " '/xds_nfs/edp_processed/BASIC/2022/Oct/1/31770605/1.203831018.bz2',\n",
       " '/xds_nfs/edp_processed/BASIC/2022/Oct/1/31770607/1.203830585.bz2',\n",
       " '/xds_nfs/edp_processed/BASIC/2022/Oct/1/31788403/1.204181749.bz2',\n",
       " '/xds_nfs/edp_processed/BASIC/2022/Oct/1/31781610/1.204044205.bz2',\n",
       " '/xds_nfs/edp_processed/BASIC/2022/Oct/1/31788559/1.204181204.bz2']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists_of_files['10_2022'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the number of file names obtained with `DownloadListOfFiles` match the previous file count per month obtained with `GetAdvBasketDataSize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:27:10.790084Z",
     "iopub.status.busy": "2023-02-03T06:27:10.789083Z",
     "iopub.status.idle": "2023-02-03T06:27:10.819087Z",
     "shell.execute_reply": "2023-02-03T06:27:10.817081Z",
     "shell.execute_reply.started": "2023-02-03T06:27:10.790084Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: len(v) for k, v in lists_of_files.items()} == {k: v['fileCount'] for k, v in sizes_counts.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yP9RcoWG2uiQ"
   },
   "source": [
    "# Download data files with `DownloadFile`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data files with **asynchronous requests** using the endpoint `DownloadFile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:27:38.795744Z",
     "iopub.status.busy": "2023-02-03T06:27:38.794743Z",
     "iopub.status.idle": "2023-02-03T06:27:38.813749Z",
     "shell.execute_reply": "2023-02-03T06:27:38.810751Z",
     "shell.execute_reply.started": "2023-02-03T06:27:38.795744Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "BASE_PATH = '../data/raw/betfair/'\n",
    "URL_DOWNLOAD = 'https://historicdata.betfair.com/api/DownloadFile'\n",
    "# headers\n",
    "headers = {\"ssoid\": token}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define 3 asynchronous functions:  \n",
    "- one to make a specific download;  \n",
    "- one to wrap a list of requests (tasks);\n",
    "- one to run a complete round of downloads for all lists of files (recall that we have a list of files for each month of data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:27:40.591748Z",
     "iopub.status.busy": "2023-02-03T06:27:40.590750Z",
     "iopub.status.idle": "2023-02-03T06:27:40.637749Z",
     "shell.execute_reply": "2023-02-03T06:27:40.633744Z",
     "shell.execute_reply.started": "2023-02-03T06:27:40.590750Z"
    }
   },
   "outputs": [],
   "source": [
    "async def async_download_file(session, url, base_path, params, headers, previously_downloaded_filepaths, timeout, retries):\n",
    "    \"\"\"\n",
    "    This function makes an asynchronous GET request using the aiohttp library. \n",
    "    If the filePath specified in params has already been downloaded, the function returns the filePath.\n",
    "    Otherwise, the function attempts to make a GET request to a maximum of `retries` number of times (or until the request is successful).\n",
    "    If the GET request is successful, the function writes the content of the response to a file in the directory specified by BASE_PATH. \n",
    "    The function then returns the filePath of the written file.\n",
    "    If the GET request is unsuccessful, the function returns None.\n",
    "\n",
    "    Parameters:\n",
    "    session (aiohttp.ClientSession): A session instance from the aiohttp library.\n",
    "    url (str): URL to make the GET request to.\n",
    "    base_path (str): path to base folder where files will be written.\n",
    "    params (dict): Dictionary of parameters with the file path to include in the GET request. \n",
    "        Schema: {\"filePath\": file_path}\n",
    "    headers (dict): Dictionary of headers to include in the GET request. \n",
    "        Schema: {\"ssoid\": token}, where `token` is a valid session token.\n",
    "    previously_downloaded_filepaths (list): List of previously downloaded file paths.\n",
    "    timeout (int or float): Timeout value in seconds for the GET request.\n",
    "    retries (int): Number of times to retry the GET request if it fails.\n",
    "\n",
    "    Returns:\n",
    "    str: The file path of the written file if the GET request is successful \n",
    "    (or if it has already been downloaded as per `previously_downloaded_filepaths`).\n",
    "    None: If the GET request is unsuccessful.\n",
    "    \"\"\"\n",
    "\n",
    "    if params['filePath'] in previously_downloaded_filepaths:\n",
    "        return params['filePath']\n",
    "    retry_count = 0\n",
    "    while retry_count < retries:\n",
    "        try:\n",
    "            async with session.get(url, params=params, headers=headers, timeout=timeout) as response:\n",
    "                if response.status != 200:\n",
    "                    retry_count += 1\n",
    "                    continue\n",
    "                dir_path_to_write = os.path.join(base_path, os.path.dirname(params['filePath'])[1::])\n",
    "                file_path_to_write = os.path.join(base_path, params['filePath'][1::])\n",
    "                if not os.path.exists(dir_path_to_write):\n",
    "                    os.makedirs(dir_path_to_write)\n",
    "                async for data in response.content.iter_chunked(1024):\n",
    "                    async with aiofiles.open(file_path_to_write, 'ba') as f:\n",
    "                        await f.write(data)\n",
    "                return params['filePath']\n",
    "        except (aiohttp.ClientError, asyncio.TimeoutError, json.JSONDecodeError):\n",
    "            retry_count += 1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:27:43.011693Z",
     "iopub.status.busy": "2023-02-03T06:27:43.011693Z",
     "iopub.status.idle": "2023-02-03T06:27:43.036699Z",
     "shell.execute_reply": "2023-02-03T06:27:43.033695Z",
     "shell.execute_reply.started": "2023-02-03T06:27:43.011693Z"
    }
   },
   "outputs": [],
   "source": [
    "async def async_download_multiple_files(url, base_path, params_list, headers, previously_downloaded_filepaths, timeout=10, retries=20):\n",
    "    \"\"\"\n",
    "    Asynchronously download multiple files from a URL.\n",
    "    This function uses the aiohttp library to download multiple files in parallel. \n",
    "    If a file has already been downloaded, it is not re-downloaded. \n",
    "    The function returns a list of file paths for all files that were downloaded successfully.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): URL to download files from.\n",
    "    base_path (str): path to base folder where files will be written.\n",
    "    params_list (list): List of dictionaries of parameters, each with a \"filePath\" key specifying the file path to include in the GET request.\n",
    "         Schema: [{\"filePath\": file_path1}, {\"filePath\": file_path2}, ...]\n",
    "    headers (dict): Dictionary of headers to include in the GET request. \n",
    "        Schema: {\"ssoid\": token}, where `token` is a valid session token.\n",
    "    previously_downloaded_filepaths (list): List of paths of previously downloaded files.\n",
    "    timeout (int or float): Timeout value in seconds for each GET request.\n",
    "    retries (int): Number of times to retry each GET request if it fails.\n",
    "    \n",
    "    Returns:\n",
    "    List[str]: List of file paths of the written files that were successfully downloaded.\n",
    "    (or previously downloaded as per `previously_downloaded_filepaths`).\n",
    "    \"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [async_download_file(session, url, base_path, params, headers, \n",
    "                                  previously_downloaded_filepaths, timeout, retries) \n",
    "                 for params in params_list]\n",
    "        downloaded_files = await asyncio.gather(*tasks, return_exceptions=False)\n",
    "        return downloaded_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:27:43.486694Z",
     "iopub.status.busy": "2023-02-03T06:27:43.485693Z",
     "iopub.status.idle": "2023-02-03T06:27:43.523690Z",
     "shell.execute_reply": "2023-02-03T06:27:43.521701Z",
     "shell.execute_reply.started": "2023-02-03T06:27:43.486694Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def run_round_of_downloads(lists_of_files_to_download, lists_of_downloaded_files, url, base_path, headers):\n",
    "    \"\"\"\n",
    "    Download multiple files in parallel for each pair `month_year` in lists_of_files_to_download.\n",
    "    Keep track of downloaded files per category in lists_of_downloaded_files.\n",
    "\n",
    "    Params:\n",
    "    lists_of_files_to_download (dict): maps a pair `month_year` to a list of file paths to download.\n",
    "        Schema: {'month_year': [file_path1, file_path2]}, \n",
    "        like in {'5_2015': ['/xds_nfs/hdfs_supreme/BASIC/2015/May/1/27433050/1.118512110.bz2',\n",
    "                            '/xds_nfs/hdfs_supreme/BASIC/2015/May/1/27433196/1.118516429.bz2',\n",
    "                            ...]}\n",
    "    lists_of_downloaded_files (dict):  maps a pair `month_year` to a list of previously downloaded file paths.\n",
    "        Schema: same as lists_of_files_to_download's.\n",
    "    url (str): URL to make the GET request to.\n",
    "    base_path (str): base file path to save downloaded files.\n",
    "    headers (dict): Dictionary of headers to include in the GET request. \n",
    "        Schema: {\"ssoid\": token}, where `token` is a valid session token.\n",
    "    Returns:\n",
    "\n",
    "    lists_of_downloaded_files (dict): updated dictionary of downloaded files per pair `month_year`.\n",
    "    \"\"\"\n",
    "\n",
    "    if not lists_of_downloaded_files:\n",
    "        lists_of_downloaded_files = {}\n",
    "\n",
    "    for k, v in lists_of_files_to_download.items():\n",
    "        params_list = [{\"filePath\": file_path} for file_path in v]\n",
    "        if k in lists_of_downloaded_files:\n",
    "            previously_downloaded_filepaths = lists_of_downloaded_files[k]\n",
    "        else:\n",
    "            previously_downloaded_filepaths = []\n",
    "        lists_of_downloaded_files[k] = await async_download_multiple_files(url, base_path, params_list, headers, previously_downloaded_filepaths)\n",
    "    \n",
    "    return lists_of_downloaded_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform downloads. In the previous section we named the full dictionary with all lists of files as `lists_of_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists_of_downloaded_files = await run_round_of_downloads(lists_of_files, None, URL_DOWNLOAD, BASE_PATH, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In practice, a single call of the asynchronous function `run_round_of_downloads` was not sufficient to download all files, as the connection with the API led to many timeouts.  \n",
    "These were not serious issues, and with more rounds of requests and retries, all files were downloaded.  \n",
    "Below is an ilustrative example of a round of downloads, for 5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:33:50.565324Z",
     "iopub.status.busy": "2023-02-03T06:33:50.565324Z",
     "iopub.status.idle": "2023-02-03T06:33:50.588321Z",
     "shell.execute_reply": "2023-02-03T06:33:50.585320Z",
     "shell.execute_reply.started": "2023-02-03T06:33:50.565324Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lists_of_files_to_download_example = {k: v[:5] for k, v in lists_of_files.items() if k == '4_2015'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:33:51.518010Z",
     "iopub.status.busy": "2023-02-03T06:33:51.516993Z",
     "iopub.status.idle": "2023-02-03T06:33:51.541995Z",
     "shell.execute_reply": "2023-02-03T06:33:51.538995Z",
     "shell.execute_reply.started": "2023-02-03T06:33:51.518010Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4_2015': ['/xds_nfs/hdfs_supreme/BASIC/2015/Apr/29/27427653/1.118400175.bz2',\n",
       "  '/xds_nfs/hdfs_supreme/BASIC/2015/Apr/29/27425814/1.118368559.bz2',\n",
       "  '/xds_nfs/hdfs_supreme/BASIC/2015/Apr/30/27433160/1.118515985.bz2',\n",
       "  '/xds_nfs/hdfs_supreme/BASIC/2015/Apr/30/27428030/1.118406188.bz2',\n",
       "  '/xds_nfs/hdfs_supreme/BASIC/2015/Apr/30/27427545/1.118394357.bz2']}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists_of_files_to_download_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:33:53.041150Z",
     "iopub.status.busy": "2023-02-03T06:33:53.040147Z",
     "iopub.status.idle": "2023-02-03T06:35:09.123261Z",
     "shell.execute_reply": "2023-02-03T06:35:09.121284Z",
     "shell.execute_reply.started": "2023-02-03T06:33:53.041150Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lists_of_downloaded_files_example = await run_round_of_downloads(lists_of_files_to_download_example, None, URL_DOWNLOAD, '../data/test/', headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:35:09.129262Z",
     "iopub.status.busy": "2023-02-03T06:35:09.128263Z",
     "iopub.status.idle": "2023-02-03T06:35:09.154261Z",
     "shell.execute_reply": "2023-02-03T06:35:09.152260Z",
     "shell.execute_reply.started": "2023-02-03T06:35:09.129262Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4_2015': ['/xds_nfs/hdfs_supreme/BASIC/2015/Apr/29/27427653/1.118400175.bz2',\n",
       "  '/xds_nfs/hdfs_supreme/BASIC/2015/Apr/29/27425814/1.118368559.bz2',\n",
       "  '/xds_nfs/hdfs_supreme/BASIC/2015/Apr/30/27433160/1.118515985.bz2',\n",
       "  '/xds_nfs/hdfs_supreme/BASIC/2015/Apr/30/27428030/1.118406188.bz2',\n",
       "  '/xds_nfs/hdfs_supreme/BASIC/2015/Apr/30/27427545/1.118394357.bz2']}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists_of_downloaded_files_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 5 files were indeed downloaded. Write dictionary as `JSON`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:35:17.038006Z",
     "iopub.status.busy": "2023-02-03T06:35:17.037007Z",
     "iopub.status.idle": "2023-02-03T06:35:17.068007Z",
     "shell.execute_reply": "2023-02-03T06:35:17.066005Z",
     "shell.execute_reply.started": "2023-02-03T06:35:17.038006Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LISTS_OF_DOWNLOADED_FILES_PATH = '../data/raw/betfair/lists_of_downloaded_files_example.json'\n",
    "\n",
    "with open(LISTS_OF_DOWNLOADED_FILES_PATH, \"w\") as outfile:\n",
    "    json.dump(lists_of_downloaded_files_example, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check if the files physically in the hard drive indeed correspond to the full list of files we intended to download.  \n",
    "We check the full list of ~300k files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:37:36.124587Z",
     "iopub.status.busy": "2023-02-03T06:37:36.123584Z",
     "iopub.status.idle": "2023-02-03T06:37:36.153583Z",
     "shell.execute_reply": "2023-02-03T06:37:36.151582Z",
     "shell.execute_reply.started": "2023-02-03T06:37:36.124587Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_files(file_path, file_type):\n",
    "    \"\"\"\n",
    "    Walks through a file path and returns all files that have the specified file type.\n",
    "    \n",
    "    Params:\n",
    "    file_path (str): The directory to search for files in and its subdirectories.\n",
    "    file_type (str): The file extension to search for (e.g. '.txt', '.pdf').\n",
    "    \n",
    "    Returns:\n",
    "    matching_files (list): A list of filenames that have the specified file type.\n",
    "    \"\"\"\n",
    "    matching_files = []\n",
    "    for dir_path, dir_names, file_names in os.walk(file_path):\n",
    "        for filename in file_names:\n",
    "            if filename.lower().endswith(file_type.lower()):\n",
    "                matching_files.append(filename)\n",
    "    return matching_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:37:39.094143Z",
     "iopub.status.busy": "2023-02-03T06:37:39.093155Z",
     "iopub.status.idle": "2023-02-03T06:40:15.478443Z",
     "shell.execute_reply": "2023-02-03T06:40:15.476443Z",
     "shell.execute_reply.started": "2023-02-03T06:37:39.094143Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# downloaded files are .bz2 files\n",
    "downloaded_files_in_hd = list_files(BASE_PATH, '.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T18:26:12.133311Z",
     "iopub.status.busy": "2023-02-01T18:26:12.132311Z",
     "iopub.status.idle": "2023-02-01T18:26:12.158312Z",
     "shell.execute_reply": "2023-02-01T18:26:12.156315Z",
     "shell.execute_reply.started": "2023-02-01T18:26:12.133311Z"
    }
   },
   "source": [
    "Now we compare `downloaded_files_in_hd` with the original `lists_of_files` to be downloaded.  \n",
    "As `lists_of_files` is a dictionary with lists, we flatten it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:42:40.911960Z",
     "iopub.status.busy": "2023-02-03T06:42:40.910964Z",
     "iopub.status.idle": "2023-02-03T06:42:41.537958Z",
     "shell.execute_reply": "2023-02-03T06:42:41.535961Z",
     "shell.execute_reply.started": "2023-02-03T06:42:40.911960Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lists_of_files_flattened = [item.split(\"/\")[-1] for sublist in lists_of_files.values() for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T06:42:42.237032Z",
     "iopub.status.busy": "2023-02-03T06:42:42.236041Z",
     "iopub.status.idle": "2023-02-03T06:42:42.569031Z",
     "shell.execute_reply": "2023-02-03T06:42:42.567030Z",
     "shell.execute_reply.started": "2023-02-03T06:42:42.237032Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(downloaded_files_in_hd) == set(lists_of_files_flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both sets match, so all files were downloaded successfully."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
